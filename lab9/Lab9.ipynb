{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation (40 points total)\n",
    "### [20 points] Define and prepare your class variables. Use proper variable representations (int, float, one-hot, etc.). Use pre-processing methods (as needed) for dimensionality reduction, scaling, etc. Remove variables that are not needed/useful for the analysis. Describe the final dataset that is used for classification/regression (include a description of any newly formed variables you created).   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 0\n",
      "Character                                                         \n",
      "Stan                    You guys, you guys! Chef is going away. \\n\n",
      "Kyle                                   Going away? For how long?\\n\n",
      "Stan                                                    Forever.\\n\n",
      "Chef                                             I'm sorry boys.\\n\n",
      "Stan             Chef said he's been bored, so he joining a gro...\n",
      "Chef                                                        Wow!\\n\n",
      "Mrs. Garrison    Chef?? What kind of questions do you think adv...\n",
      "Chef                What's the meaning of life? Why are we here?\\n\n",
      "Mrs. Garrison             I hope you're making the right choice.\\n\n",
      "Cartman          I'm gonna miss him.  I'm gonna miss Chef and I...\n",
      "Stan             Dude, how are we gonna go on? Chef was our fuh...\n",
      "Mayor McDaniels  And we will all miss you, Chef,  but we know y...\n",
      "Jimbo                                                   Bye-bye!\\n\n",
      "Gerald                                                 Good-bye!\\n\n",
      "Mr. Mackey                                              So long!\\n\n",
      "A Man                                             So long, Chef!\\n\n",
      "A Sign-Holder                                    Good-bye, Chef!\\n\n",
      "Randy            Good-bye, Chef! Have a great time with the Sup...\n",
      "Chef                                                Good-bye! ..\\n\n",
      "Kyle                                      Draw two card, fatass.\\n\n",
      "Cartman                                    Reverse to you, Jew. \\n\n",
      "Stan                                               I'll get it. \\n\n",
      "Chef                                      Hello there, children!\\n\n",
      "Stan                                                  He's back!\\n\n",
      "Kyle                                                       Yeah!\\n\n",
      "Cartman                                              All right! \\n\n",
      "Kyle                          Chef! I can't believe you're back!\\n\n",
      "Chef                                            Well, it's true.\\n\n",
      "Stan                                  But are you back for good?\\n\n",
      "Chef                                               That's right.\\n\n",
      "...                                                            ...\n",
      "Randy            You heard what he said!  The higher power didn...\n",
      "Man 10                              I'm, I'm, I'm powerless too!\\n\n",
      "Man 11                                              Yeah me too!\\n\n",
      "Man 10                                    Get me seven martinis!\\n\n",
      "Man 12                                            Jack and Coke!\\n\n",
      "Stan                                             Dad, Dad, Stop!\\n\n",
      "Randy                         I'm sorry, son! I'm off the wagon!\\n\n",
      "Stan             Dad, you don't have to do this! You have the p...\n",
      "Randy                           But the statue wasn't a miracle!\\n\n",
      "Stan             Yeah. The statue wasn't a miracle, Dad. So tha...\n",
      "Randy            You're right, Stan. If God didn't make me stop...\n",
      "Stan                                                         No!\\n\n",
      "Randy                                                       No??\\n\n",
      "Stan             Dad, you like to drink. So have a drink once i...\n",
      "Randy            But, maybe... I'm just the kind of person who ...\n",
      "Stan             Naw. All or nothing is easy. But learning to d...\n",
      "Randy                How did I manage to raise such a smart kid?\\n\n",
      "Stan                                   I've had a great teacher.\\n\n",
      "Randy                                                Thanks son.\\n\n",
      "Stan             No not you, my karate teacher. He's really sma...\n",
      "Randy            Oh. Well, tell you what: let's leave the car h...\n",
      "Stan                                                  All right!\\n\n",
      "Randy                 Come on!  Or maybe I'll have three beers. \\n\n",
      "Stan                  That's probably okay if you spread it out.\\n\n",
      "Randy                                       Well how about four?\\n\n",
      "Stan                                  I think you're pushing it.\\n\n",
      "Randy                                          How about twenty?\\n\n",
      "Stan                                      That's not disciprine.\\n\n",
      "Randy                             Right right. Does vodka count?\\n\n",
      "Stan                                                        Dad!\\n\n",
      "\n",
      "[70896 rows x 1 columns]\n",
      "                                                                  0\n",
      "Character                                                          \n",
      "Kyle                                    Going away? For how long?\\n\n",
      "Chef                                              I'm sorry boys.\\n\n",
      "Chef                                                         Wow!\\n\n",
      "Mrs. Garrison     Chef?? What kind of questions do you think adv...\n",
      "Chef                 What's the meaning of life? Why are we here?\\n\n",
      "Mrs. Garrison              I hope you're making the right choice.\\n\n",
      "Cartman           I'm gonna miss him.  I'm gonna miss Chef and I...\n",
      "Mayor McDaniels   And we will all miss you, Chef,  but we know y...\n",
      "Jimbo                                                    Bye-bye!\\n\n",
      "Gerald                                                  Good-bye!\\n\n",
      "Mr. Mackey                                               So long!\\n\n",
      "A Man                                              So long, Chef!\\n\n",
      "A Sign-Holder                                     Good-bye, Chef!\\n\n",
      "Randy             Good-bye, Chef! Have a great time with the Sup...\n",
      "Chef                                                 Good-bye! ..\\n\n",
      "Kyle                                       Draw two card, fatass.\\n\n",
      "Cartman                                     Reverse to you, Jew. \\n\n",
      "Chef                                       Hello there, children!\\n\n",
      "Kyle                                                        Yeah!\\n\n",
      "Cartman                                               All right! \\n\n",
      "Kyle                           Chef! I can't believe you're back!\\n\n",
      "Chef                                             Well, it's true.\\n\n",
      "Chef                                                That's right.\\n\n",
      "Mrs. Garrison                         Hey everybody! Chef's back!\\n\n",
      "Patrons                                   What? All right! Yeah! \\n\n",
      "Randy                                               Oh, finally! \\n\n",
      "Gerald            Wow! It seems like you had a great time with t...\n",
      "Chef                                                        Yeah!\\n\n",
      "Mrs. Garrison     But now that you're back here, does that mean ...\n",
      "Chef                                                       Nnono!\\n\n",
      "...                                                             ...\n",
      "Randy                             I'm Randy and I'm an alcoholic.\\n\n",
      "Group                                                   Hi Randy.\\n\n",
      "Randy             But I put my faith in a higher power and... I ...\n",
      "Field Reporter    An update from the bleeding Virgin Mary statue!\\n\n",
      "Randy                    Oh wait. Sh sh. Hold on a second, gang. \\n\n",
      "Field Reporter    Earlier today, the new pope, Pope Benedict the...\n",
      "Cardinal Mallory                   Right this way, Your Holiness.\\n\n",
      "Field Reporter    The pope then examined the statue closely.  Af...\n",
      "Randy                                                       What?\\n\n",
      "Field Reporter    Having investigated closely, the pope determin...\n",
      "Tom               Thanks, Edward, that's a very shocking report....\n",
      "Randy             That means... I'm not cured. I still have the ...\n",
      "Michael                             Randy, uh what are you doing?\\n\n",
      "Randy             You heard what he said!  The higher power didn...\n",
      "Man 10                               I'm, I'm, I'm powerless too!\\n\n",
      "Man 11                                               Yeah me too!\\n\n",
      "Man 10                                     Get me seven martinis!\\n\n",
      "Man 12                                             Jack and Coke!\\n\n",
      "Randy                          I'm sorry, son! I'm off the wagon!\\n\n",
      "Randy                            But the statue wasn't a miracle!\\n\n",
      "Randy             You're right, Stan. If God didn't make me stop...\n",
      "Randy                                                        No??\\n\n",
      "Randy             But, maybe... I'm just the kind of person who ...\n",
      "Randy                 How did I manage to raise such a smart kid?\\n\n",
      "Randy                                                 Thanks son.\\n\n",
      "Randy             Oh. Well, tell you what: let's leave the car h...\n",
      "Randy                  Come on!  Or maybe I'll have three beers. \\n\n",
      "Randy                                        Well how about four?\\n\n",
      "Randy                                           How about twenty?\\n\n",
      "Randy                              Right right. Does vodka count?\\n\n",
      "\n",
      "[63216 rows x 1 columns]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Character'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mpandas\\index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_loc (pandas\\index.c:4279)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\src\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas.hashtable.Int64HashTable.get_item (pandas\\hashtable.c:8543)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: an integer is required",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mD:\\Programming\\Anaconda\\envs\\tensor\\lib\\site-packages\\pandas\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2133\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2134\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2135\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_loc (pandas\\index.c:4433)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_loc (pandas\\index.c:4363)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Character'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mpandas\\index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_loc (pandas\\index.c:4279)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\src\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas.hashtable.Int64HashTable.get_item (pandas\\hashtable.c:8543)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: an integer is required",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-92-130caa5323eb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[0my_string\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Character'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[0muniques\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_ints\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcounts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_string\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_inverse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mreturn_counts\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[0mnum_classes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programming\\Anaconda\\envs\\tensor\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2057\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2058\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2059\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2060\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2061\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programming\\Anaconda\\envs\\tensor\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_getitem_column\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2064\u001b[0m         \u001b[1;31m# get column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2065\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2066\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2067\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2068\u001b[0m         \u001b[1;31m# duplicate columns & possible reduce dimensionality\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programming\\Anaconda\\envs\\tensor\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_get_item_cache\u001b[1;34m(self, item)\u001b[0m\n\u001b[0;32m   1384\u001b[0m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1385\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1386\u001b[1;33m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1387\u001b[0m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_box_item_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1388\u001b[0m             \u001b[0mcache\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programming\\Anaconda\\envs\\tensor\\lib\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, item, fastpath)\u001b[0m\n\u001b[0;32m   3541\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3542\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misnull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3543\u001b[1;33m                 \u001b[0mloc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3544\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3545\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0misnull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programming\\Anaconda\\envs\\tensor\\lib\\site-packages\\pandas\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2134\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2135\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2136\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2137\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2138\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_loc (pandas\\index.c:4433)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_loc (pandas\\index.c:4363)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Character'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "df = pd.read_csv('./south-park-dialogue/All-seasons.csv')\n",
    "df = pd.DataFrame(df.drop(['Character', 'Season', 'Episode'], axis=1).values, index=df['Character'])\n",
    "\n",
    "y_string = df['Character'].values\n",
    "uniques, y_ints, counts = np.unique(y_string, return_inverse=True,return_counts=True)\n",
    "num_classes = len(uniques)\n",
    "\n",
    "X_preprep = df.drop(['Character', 'Season', 'Episode'], axis=1).values\n",
    "    \n",
    "X_preprep = X_preprep.flatten()\n",
    "\n",
    "y_ohe = keras.utils.to_categorical(y_ints, num_classes)\n",
    "\n",
    "print(counts)\n",
    "print(uniques)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "NUM_TOP_WORDS = None\n",
    "padding = 100\n",
    "\n",
    "tokenizer = Tokenizer(num_words=NUM_TOP_WORDS)\n",
    "tokenizer.fit_on_texts(X_preprep)\n",
    "sequences = tokenizer.texts_to_sequences(X_preprep)\n",
    "\n",
    "X = pad_sequences(sequences, maxlen=padding)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embeddings_index = {}\n",
    "word_index = tokenizer.word_index\n",
    "embed_size = 100\n",
    "\n",
    "f = open('glove.6B/glove.6B.100d.txt', encoding='utf-8')\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "\n",
    "embedding_matrix = np.zeros((len(word_index) + 1, embed_size))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [10 points] Choose and explain what metric(s) you will use to evaluate your algorithmâ€™s performance. You should give a detailed argument for why this (these) metric(s) are appropriate on your data. That is, why is the metric appropriate for the task (e.g., in terms of the business case for the task). Please note: rarely is accuracy the best evaluation metric to use. Think deeply about an appropriate measure of performance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [10 points] Choose the method you will use for dividing your data into training and testing (i.e., are you using Stratified 10-fold cross validation? Shuffle splits? Why?). Explain why your chosen method is appropriate or use more than one method as appropriate. Convince me that your cross validation method is a realistic mirroring of how an algorithm would be used in practice. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# X_train, X_test, y_train_ohe, y_test_ohe = train_test_split(X, y_ohe, test_size=0.2, stratify=y_string, random_state=8)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling (50 points total)\n",
    "### [25 points] Investigate at least two different recurrent network architectures (perhaps LSTM and GRU). Adjust hyper-parameters of the networks as needed to improve generalization performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Embedding\n",
    "\n",
    "embedding_layer = Embedding(len(word_index) + 1,\n",
    "                            embed_size,\n",
    "                            weights=[embedding_matrix],\n",
    "                            input_length=padding,\n",
    "                            trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 100, 100)          2684000   \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 20)                9680      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 3950)              82950     \n",
      "=================================================================\n",
      "Total params: 2,776,630\n",
      "Trainable params: 92,630\n",
      "Non-trainable params: 2,684,000\n",
      "_________________________________________________________________\n",
      "None\n",
      "Wall time: 742 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "\n",
    "lstm_rnn = Sequential()\n",
    "lstm_rnn.add(embedding_layer)\n",
    "lstm_rnn.add(LSTM(100, dropout=.2, recurrent_dropout=.2))\n",
    "lstm_rnn.add(Dense(num_classes, activation='sigmoid'))\n",
    "\n",
    "lstm_rnn.compile(loss='categorical_crossentropy', \n",
    "              optimizer='rmsprop', \n",
    "              metrics=['accuracy'])\n",
    "print(lstm_rnn.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 70896 samples, validate on 70896 samples\n",
      "Epoch 1/3\n",
      "70896/70896 [==============================] - 122s - loss: 5.1229 - acc: 0.1379 - val_loss: 5.0599 - val_acc: 0.1379\n",
      "Epoch 2/3\n",
      "70896/70896 [==============================] - 126s - loss: 5.0985 - acc: 0.1379 - val_loss: 5.0320 - val_acc: 0.1378\n",
      "Epoch 3/3\n",
      "70896/70896 [==============================] - 125s - loss: 5.0787 - acc: 0.1378 - val_loss: 5.0153 - val_acc: 0.1377\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x19e2db91eb8>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_rnn.fit(X, y_ohe, validation_data=(X, y_ohe), epochs=3, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 70896 samples, validate on 70896 samples\n",
      "Epoch 1/3\n",
      "70896/70896 [==============================] - 122s - loss: 5.0655 - acc: 0.1378 - val_loss: 5.0094 - val_acc: 0.1379\n",
      "Epoch 2/3\n",
      "70896/70896 [==============================] - 120s - loss: 5.0621 - acc: 0.1376 - val_loss: 5.0052 - val_acc: 0.1376\n",
      "Epoch 3/3\n",
      "70896/70896 [==============================] - 126s - loss: 5.0610 - acc: 0.1380 - val_loss: 5.0090 - val_acc: 0.1381\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x19e2fa7a160>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_rnn.fit(X, y_ohe, validation_data=(X, y_ohe), epochs=3, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 100, 100)          2684000   \n",
      "_________________________________________________________________\n",
      "gru_1 (GRU)                  (None, 20)                7260      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 3950)              82950     \n",
      "=================================================================\n",
      "Total params: 2,774,210\n",
      "Trainable params: 90,210\n",
      "Non-trainable params: 2,684,000\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import GRU\n",
    "\n",
    "gru_rnn = Sequential()\n",
    "gru_rnn.add(embedding_layer)\n",
    "gru_rnn.add(GRU(100, dropout=.2, recurrent_dropout=.2))\n",
    "gru_rnn.add(Dense(num_classes, activation='sigmoid'))\n",
    "\n",
    "gru_rnn.compile(loss='categorical_crossentropy', \n",
    "              optimizer='rmsprop', \n",
    "              metrics=['accuracy'])\n",
    "print(gru_rnn.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 70896 samples, validate on 70896 samples\n",
      "Epoch 1/3\n",
      "70896/70896 [==============================] - 100s - loss: 5.7932 - acc: 0.1374 - val_loss: 5.2541 - val_acc: 0.1379\n",
      "Epoch 2/3\n",
      "70896/70896 [==============================] - 102s - loss: 5.2601 - acc: 0.1379 - val_loss: 5.1481 - val_acc: 0.13791\n",
      "Epoch 3/3\n",
      "70896/70896 [==============================] - 102s - loss: 5.1763 - acc: 0.1377 - val_loss: 5.1042 - val_acc: 0.1366\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x19e31076eb8>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gru_rnn.fit(X, y_ohe, validation_data=(X, y_ohe), epochs=3, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 3950)\n"
     ]
    }
   ],
   "source": [
    "def data_prep(words):\n",
    "    tokened = np.array(tokenizer.texts_to_sequences(words))\n",
    "    return pad_sequences(tokened, maxlen=padding)\n",
    "\n",
    "sent = ['hello, my name is Stan']\n",
    "blegh = gru_rnn.predict(data_prep(sent))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exceptional Work (10 points total)\n",
    "You have free reign to provide additional analyses.\n",
    "### One idea: Use more than a single chain of LSTMs or GRUs (i.e., use multiple parallel chains). \n",
    "Another Idea: Try to create a RNN for generating novel text. "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
